{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "* https://github.com/fede1024/caffe-experiments/blob/master/memo.txt\n",
    "* https://github.com/TZstatsADS/Spr2016-Proj3-Grp3/blob/master/output/extractfeature.ipynb \n",
    "* https://cdn.rawgit.com/TZstatsADS/ADS_Teaching/master/Spring2016/Tutorials/wk7-image_analysis/advanced_image_analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Input\n",
    "\n",
    "* caffepath indicates the root path of the `caffe` package\n",
    "* inputpath indicates the folder which saves all the training images\n",
    "* inputpath_test indicates the folder which saves all the testing images\n",
    "* outputpath indicates the foler which the features extracted should be saved in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffepath = '/Users/YaqingXie/caffe'\n",
    "inputpath = '/Users/YaqingXie/Desktop/ADS_project5/train_images'\n",
    "outputpath = '/Users/YaqingXie/Desktop/ADS_project5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "* First, set up Python, `numpy`, `panda`, `datetime` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load `caffe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "import sys\n",
    "\n",
    "if not caffepath.endswith('/'):\n",
    "    caffepath = caffepath + '/'\n",
    "if not inputpath.endswith('/'):\n",
    "    inputpath = inputpath + '/'\n",
    "# if not inputpath_test.endswith('/'):\n",
    "#     inputpath_test = inputpath_test + '/'\n",
    "if not outputpath.endswith('/'):\n",
    "    outputpath = outputpath + '/'\n",
    "\n",
    "caffe_root = caffepath\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If needed, download the reference model (\"CaffeNet\", a variant of AlexNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaffeNet found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
    "    print('CaffeNet found.')\n",
    "else:\n",
    "    print('Downloading pre-trained CaffeNet model...')\n",
    "    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load net and set up input preprocessing\n",
    "\n",
    "* Set Caffe to CPU mode and load the net from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "\n",
    "model_def = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set up input preprocessing. (We'll use Caffe's `caffe.io.Transformer` to do this, but this step is independent of other parts of Caffe, so any custom preprocessing code may be used).\n",
    "\n",
    "    Our default CaffeNet is configured to take images in BGR format. Values are expected to start in the range [0, 255] and then have the mean ImageNet pixel value subtracted from them. In addition, the channel dimension is expected as the first (_outermost_) dimension.\n",
    "    \n",
    "    As matplotlib will load images with values in the range [0, 1] in RGB format with the channel as the _innermost_ dimension, we are arranging for the needed transformations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: <zip object at 0x124cbc248>\n"
     ]
    }
   ],
   "source": [
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print('mean-subtracted values:', zip('BGR', mu))\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the size of the input (we can skip this if we're happy\n",
    "#  with the default; we can also change it later, e.g., for different batch sizes)\n",
    "net.blobs['data'].reshape(1,        # batch size\n",
    "                          3,         # 3-channel (BGR) images\n",
    "                          227, 227)  # image size is 227x227"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "+ The more layers we extract, the better result we can get. \n",
    "+ Considering time efficiency, here we run layer Norm1 and Conv3 only. \n",
    "+ For more layers, please refer to Caffe_Features -> Feature_Extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "name_list = [f for f in listdir(inputpath) if isfile(join(inputpath, f)) and f.endswith('.jpg')]\n",
    "# name_list_test = [f for f in listdir(inputpath_test) if isfile(join(inputpath_test, f)) and f.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Layer norm1 dimensions: (1, 96, 27, 27) [69984 values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:33.373681\n",
      "Feature extraction finished.\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "a = datetime.datetime.now()\n",
    "i = 0\n",
    "image = caffe.io.load_image(str(inputpath + name_list[i]))\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "net.forward()\n",
    "feature1 = np.reshape(net.blobs['norm1'].data[0], 69984, order='C')\n",
    "for name in name_list[1:]:\n",
    "    image = caffe.io.load_image(str(inputpath + name))\n",
    "    net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "    net.forward()\n",
    "    feature1 = np.vstack([feature1,np.reshape(net.blobs['norm1'].data[0], 69984, order='C')])\n",
    "    #i += 1\n",
    "b = datetime.datetime.now()\n",
    "print(b-a)\n",
    "print('Feature extraction finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Layer conv3 dimensions: (1, 384, 13, 13) [64896 values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:04:37.138227\n",
      "Feature extraction finished.\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "a = datetime.datetime.now()\n",
    "i = 0\n",
    "image = caffe.io.load_image(str(inputpath + name_list[i]))\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "net.forward()\n",
    "feature3 = np.reshape(net.blobs['conv3'].data[0], 64896, order='C')\n",
    "for name in name_list[1:]:\n",
    "    image = caffe.io.load_image(str(inputpath + name))\n",
    "    net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "    net.forward()\n",
    "    feature3 = np.vstack([feature3,np.reshape(net.blobs['conv3'].data[0], 64896, order='C')])\n",
    "    #i += 1\n",
    "b = datetime.datetime.now()\n",
    "print(b-a)\n",
    "print('Feature extraction finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_norm1 = pd.DataFrame(feature1)\n",
    "data_conv3 = pd.DataFrame(feature3)\n",
    "# data_norm1_with_name = pd.concat([pd.DataFrame(name_list),pd.DataFrame(data_norm1)], axis=1)\n",
    "# pd.DataFrame(data_norm1_with_name).to_csv(outputpath + 'train_norm1.csv', index=False)\n",
    "data_conv3_with_name = pd.concat([pd.DataFrame(name_list),pd.DataFrame(data_conv3)], axis=1)\n",
    "pd.DataFrame(data_conv3_with_name).to_csv(outputpath + 'train_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Decomposition and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, n_components=750, whiten=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA  \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "data_norm1 = pd.DataFrame(feature1)\n",
    "data_conv3 = pd.DataFrame(feature3)\n",
    "\n",
    "pca1 = PCA(n_components=750)\n",
    "pca1.fit(data_norm1)\n",
    "pca3 = PCA(n_components=750)\n",
    "pca3.fit(data_conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957337\n",
      "0.957757\n"
     ]
    }
   ],
   "source": [
    "print(pca1.explained_variance_ratio_.sum())\n",
    "print(pca3.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_norm1_pca = pca1.transform(data_norm1)\n",
    "data_norm1_pca_with_name = pd.concat([pd.DataFrame(name_list),pd.DataFrame(data_norm1_pca)], axis=1)\n",
    "pd.DataFrame(data_norm1_pca_with_name).to_csv(outputpath + 'train_norm1_pca.csv', index=False)\n",
    "\n",
    "data_conv3_pca = pca3.transform(data_conv3)\n",
    "data_conv3_pca_with_name = pd.concat([pd.DataFrame(name_list),pd.DataFrame(data_conv3_pca)], axis=1)\n",
    "pd.DataFrame(data_conv3_pca_with_name).to_csv(outputpath + 'train_conv3_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:09:49.659188\n",
      "Feature extraction finished.\n"
     ]
    }
   ],
   "source": [
    "a = datetime.datetime.now()\n",
    "i = 0\n",
    "image = caffe.io.load_image(str(inputpath_test + name_list_test[i]))\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "net.forward()\n",
    "feature1_test = np.reshape(net.blobs['norm1'].data[0], 69984, order='C')\n",
    "for name in name_list_test[1:]:\n",
    "    image = caffe.io.load_image(str(inputpath_test + name))\n",
    "    net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "    net.forward()\n",
    "    feature1_test = np.vstack([feature1_test,np.reshape(net.blobs['norm1'].data[0], 69984, order='C')])\n",
    "    #i += 1\n",
    "b = datetime.datetime.now()\n",
    "print(b-a)\n",
    "print('Feature extraction finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:10:19.543585\n",
      "Feature extraction finished.\n"
     ]
    }
   ],
   "source": [
    "a = datetime.datetime.now()\n",
    "i = 0\n",
    "image = caffe.io.load_image(str(inputpath_test + name_list_test[i]))\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "net.forward()\n",
    "feature3_test = np.reshape(net.blobs['conv3'].data[0], 64896, order='C')\n",
    "for name in name_list_test[1:]:\n",
    "    image = caffe.io.load_image(str(inputpath_test + name))\n",
    "    net.blobs['data'].data[...] = transformer.preprocess('data', image)\n",
    "    net.forward()\n",
    "    feature3_test = np.vstack([feature3_test,np.reshape(net.blobs['conv3'].data[0], 64896, order='C')])\n",
    "    #i += 1\n",
    "b = datetime.datetime.now()\n",
    "print(b-a)\n",
    "print('Feature extraction finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_norm1 = pd.DataFrame(feature1_test)\n",
    "test_conv3 = pd.DataFrame(feature3_test)\n",
    "\n",
    "test_norm1_pca = pca.transform(test_norm1)\n",
    "test_conv3_pca = pca.transform(test_conv3)\n",
    "\n",
    "pd.DataFrame(test_norm1_pca).to_csv(outputpath + 'test_norm1_pca.csv')\n",
    "pd.DataFrame(test_conv3_pca).to_csv(outputpath + 'test_conv3_pca.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
